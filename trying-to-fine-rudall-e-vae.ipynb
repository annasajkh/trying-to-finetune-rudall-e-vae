{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rudalle==1.0.0\n!wget https://www.kaggleusercontent.com/kf/86840742/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..ZvbQWMd2ooIAxEAPDJ3vFg.GS1SW-4V3nAjJOlvs6XhYH0DKtTS433GaSeophK84LMuN7BKAHgnSr-reUOWDmr-7IUcjOCWMhmTlUb_lfMutFWkLx79OvE0QxpEravZALuRRhs-px8irtXSWiP-CmiZ5AsqSiGQmFQofCa2xoo4uQijL3V74KT3IfYDhZ6YsP9yqCFMRMSyIJ3VdhZ_SIQW85PgYqQ6BzwCTOc01AovblrNd2c6xQGf5_WdypWwZXUE92-ZU6N3RoXZNdX6AX8n0Qll7aRgc5JEYLvNF3FRUwC7gl2qdLu1XxD2kGPRbLYfdSo-zsmtB2l2aaJ4GsC3F-qt6Fvp7wrnFy1Kgz-YOlfOYcsGqDWaYmSpIG2o3kVHrLg_Ic5Y9lyWgYTdORxUAeYBR80QdqZ0_rpPJrURm1lAl3JgXzssZUFiMnnYu3Tq4ef-skuR-BxFA1ZB11zlkPHsGR3IlUh2lEwvxsCzsPS2M0sPvTrqN0cm2P56jhaPOqUwGfLosntqwMwUq_JddDZKrpfDqC5TDnwrFD_LskxxgI8WRI3ShqxovqXj8wtJARuAinJcZBWHDuK7maASug7t7iAv2MC5iReM2_9_ScGF9RYzrppblVvgBB0F4QwHXUIZnU_EZ7cMh5FIpBLrTAaT734MFgUQqyoHxHVOOsC2xG7G59pER9RnB5PSMcw.tKZqBy_k4Dh3ShxKObwmpA/model.pth","metadata":{"execution":{"iopub.status.busy":"2022-02-03T10:25:53.55144Z","iopub.execute_input":"2022-02-03T10:25:53.552478Z","iopub.status.idle":"2022-02-03T10:26:31.079759Z","shell.execute_reply.started":"2022-02-03T10:25:53.552354Z","shell.execute_reply":"2022-02-03T10:26:31.078517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from rudalle import get_vae\nimport torch.nn as nn\nfrom torch.optim import AdamW\nimport torch\nfrom IPython.display import clear_output\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nvae = get_vae().to(device)\nvae.train()\nvae.load_state_dict(torch.load(\"model.pth\"))\noptimizer = AdamW(vae.parameters(), lr=3e-4)\nloss_function = nn.MSELoss().to(device)\n\ntorch.cuda.empty_cache()\nclear_output()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-03T10:26:31.08418Z","iopub.execute_input":"2022-02-03T10:26:31.08524Z","iopub.status.idle":"2022-02-03T10:26:56.915001Z","shell.execute_reply.started":"2022-02-03T10:26:31.085188Z","shell.execute_reply":"2022-02-03T10:26:56.914143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nimport glob\nimport matplotlib.pyplot as plt\n\ndef center_crop(img):\n    width, height = img.size\n    \n    new_width, new_height = (width, width) if width < height else (height, height)\n    \n    left = (width - new_width)/2\n    top = (height - new_height)/2\n    right = (width + new_width)/2\n    bottom = (height + new_height)/2\n\n    return img.crop((left, top, right, bottom))","metadata":{"execution":{"iopub.status.busy":"2022-02-03T10:26:56.916794Z","iopub.execute_input":"2022-02-03T10:26:56.917253Z","iopub.status.idle":"2022-02-03T10:26:56.927482Z","shell.execute_reply.started":"2022-02-03T10:26:56.917205Z","shell.execute_reply":"2022-02-03T10:26:56.926501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths = [path for path in glob.glob(\"../input/coco-2017-dataset/coco2017/train2017/*\")]\nprint(len(paths))","metadata":{"execution":{"iopub.status.busy":"2022-02-03T10:26:56.930755Z","iopub.execute_input":"2022-02-03T10:26:56.931782Z","iopub.status.idle":"2022-02-03T10:26:59.445544Z","shell.execute_reply.started":"2022-02-03T10:26:56.931724Z","shell.execute_reply":"2022-02-03T10:26:59.444303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport torch\n\nbatch_size = 8\n\ntotal_loss = 0.0\n\nprint(\"starting.....2\")\n\n\nfor i in range(0, len(paths) // batch_size + 1):\n    images = [center_crop(Image.open(path).convert(\"RGB\")).resize((256, 256), Image.BICUBIC) for path in paths[(i-1) * batch_size:i * batch_size]]\n\n    if len(images) == 0:\n        continue\n\n    images = np.array([np.array(img) for img in images])\n\n    torch.cuda.empty_cache()\n\n    images = torch.tensor(images).to(device).float() / 255\n\n    torch.cuda.empty_cache()\n\n    images = torch.permute(images, (0, 3, 1, 2))\n\n    torch.cuda.empty_cache()\n\n    optimizer.zero_grad()\n\n    image_masked = images.detach().clone()\n\n    for im in image_masked:\n        for n in range(random.randrange(10, 100)):\n            w, h = (random.randrange(10, 50), random.randrange(10, 50))\n\n            box = torch.zeros(3, w, h)\n\n            x = random.randrange(0, 256 - w)\n            y = random.randrange(0, 256 - h)\n\n            im[:, x:x+w, y:y+h] = box\n\n\n    y = vae.decode(vae.get_codebook_indices(image_masked))\n    torch.cuda.empty_cache()\n\n    loss = loss_function(y, images)\n\n    clear_output()\n\n    print(f\"Steps: {i}\\nLoss: {loss.item()}\")\n\n    total_loss += loss.item()\n\n    loss.backward()\n    optimizer.step()\n\n    torch.cuda.empty_cache()\n    \n    if i % 1000 == 0:\n        torch.save(vae.state_dict(), \"model.pth\")\n\ntorch.save(vae.state_dict(), \"model.pth\")\n\ntotal_loss /= (10_000 / batch_size)\n\nprint(f\"Epoch: {1}\\nTotal Loss: {total_loss}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-02T20:42:56.208849Z","iopub.execute_input":"2022-02-02T20:42:56.209593Z","iopub.status.idle":"2022-02-02T20:43:01.361218Z","shell.execute_reply.started":"2022-02-02T20:42:56.209517Z","shell.execute_reply":"2022-02-02T20:43:01.359224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#torch.save(vae.state_dict(), \"model.pth\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install gdown\n# !gdown --id 1VxYLMzPaxbn4pk0MlZI9irBNWj8Py2cu","metadata":{"execution":{"iopub.status.busy":"2022-01-11T22:12:52.305023Z","iopub.execute_input":"2022-01-11T22:12:52.305825Z","iopub.status.idle":"2022-01-11T22:13:12.514855Z","shell.execute_reply.started":"2022-01-11T22:12:52.305755Z","shell.execute_reply":"2022-01-11T22:13:12.513983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://openai.com/content/images/2021/08/openai-avatar.png -O test.jpg","metadata":{"execution":{"iopub.status.busy":"2022-02-03T10:29:30.749744Z","iopub.execute_input":"2022-02-03T10:29:30.750133Z","iopub.status.idle":"2022-02-03T10:29:32.229854Z","shell.execute_reply.started":"2022-02-03T10:29:30.750071Z","shell.execute_reply":"2022-02-03T10:29:32.228721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\nimage = Image.open(\"./test.jpg\").convert(\"RGB\").resize((700,700), Image.BICUBIC)\ndisplay(image)\n\nimage = np.array(image)\n\nimage = (torch.tensor(image).to(device).float() / 255)[None,:]\nimage = torch.permute(image, (0, 3, 1, 2))\n\nfor im in image:\n    for n in range(random.randrange(1, 2)):\n        w, h = (random.randrange(200, 500), random.randrange(200, 500))\n\n        box = torch.zeros(3, w, h)\n\n        x = random.randrange(0, 700 - w)\n        y = random.randrange(0, 700 - h)\n\n        im[:, x:x+w, y:y+h] = box\n\nm = torch.squeeze(image.detach().clone()).permute(1,2,0).detach().cpu().numpy()\nm = Image.fromarray((m * 255).astype(\"uint8\"))\n\ndisplay(m)\n\ncode = vae.get_codebook_indices(image)\ny = vae.decode(code)\n\nm = torch.squeeze(y).permute(1,2,0).detach().cpu().numpy()\nm = Image.fromarray((m * 255).astype(\"uint8\"))\n\ndisplay(m)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T10:35:33.813341Z","iopub.execute_input":"2022-02-03T10:35:33.813691Z","iopub.status.idle":"2022-02-03T10:35:34.809654Z","shell.execute_reply.started":"2022-02-03T10:35:33.813643Z","shell.execute_reply":"2022-02-03T10:35:34.807909Z"},"trusted":true},"execution_count":null,"outputs":[]}]}